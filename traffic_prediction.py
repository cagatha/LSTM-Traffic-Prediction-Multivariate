# -*- coding: utf-8 -*-
"""traffic prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uZ1uBd5Nd33kRGKPhLgaWk_h-Cx_hI1C
"""

import torch
import torchvision as ptv
import numpy as np
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from google.colab import drive
import pandas as pd
import matplotlib.pyplot as plt
import torch.nn as nn
from torch.autograd import Variable
from sklearn.preprocessing import MinMaxScaler

import tensorflow as tf
import os
import pandas as pd
import numpy as np

drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Deep Learning/Alvin/my practice

traffic_df = pd.read_csv('traffic.csv')
traffic_df.shape
traffic_df.head()

vehicles=traffic_df.iloc[:,2:3].values

plt.plot(vehicles, label = 'Vehicles over Time')
plt.show()

def sliding_windows(data, seq_length):
    x = []
    y = []

    for i in range(len(data)-seq_length-1):
        _x = data[i:(i+seq_length)]
        _y = data[i+seq_length]
        x.append(_x)
        y.append(_y)

    return np.array(x),np.array(y)

sc = MinMaxScaler()
vehicles = sc.fit_transform(vehicles)

seq_length = 4
X1, y1 = sliding_windows(vehicles, seq_length)

trainX = Variable(torch.Tensor(np.array(X1[:30000])))
trainY = Variable(torch.Tensor(np.array(y1[:30000])))

valX = Variable(torch.Tensor(np.array(X1[30000:39000])))
valY = Variable(torch.Tensor(np.array(y1[30000:39000])))

testX = Variable(torch.Tensor(np.array(X1[39000:])))
testY = Variable(torch.Tensor(np.array(y1[39000:])))

class LSTM(nn.Module):

    def __init__(self, num_classes, input_size, hidden_size, num_layers):
        super(LSTM, self).__init__()

        self.num_classes = num_classes
        self.num_layers = num_layers
        self.input_size = input_size
        self.hidden_size = hidden_size


        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,
                            num_layers=num_layers, batch_first=True)

        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        h_0 = Variable(torch.zeros(
            self.num_layers, x.size(0), self.hidden_size))

        c_0 = Variable(torch.zeros(
            self.num_layers, x.size(0), self.hidden_size))

        # Propagate input through LSTM
        ula, (h_out, _) = self.lstm(x, (h_0, c_0))

        h_out = h_out.view(-1, self.hidden_size)

        out = self.fc(h_out)

        return out

num_epochs = 2000
learning_rate = 0.01

input_size = 1
hidden_size = 2
num_layers = 1

num_classes = 1

lstm = LSTM(num_classes, input_size, hidden_size, num_layers)

criterion = torch.nn.MSELoss()    # mean-squared error for regression
optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)

# Train the model
for epoch in range(num_epochs):
    outputs = lstm(trainX)
    optimizer.zero_grad()

    # obtain the loss function
    loss = criterion(outputs, trainY)

    loss.backward()

    optimizer.step()
    if epoch % 100 == 0:
      print("Epoch: %d, loss: %1.5f" % (epoch, loss.item()))

torch.save(lstm.state_dict(), 'trained_lstm_model_parameters.pth')

lstm.eval()
train_predict = lstm(trainX)

train_predict = train_predict.data.numpy()
train_actual = trainY.data.numpy()
train_predict = sc.inverse_transform(train_predict)
train_actual = sc.inverse_transform(train_actual)

df_train_predict = pd.DataFrame(train_predict, columns=['Predicted'])
df_train_actual = pd.DataFrame(train_actual, columns=['Actual'])

df_train_predict['Index'] = df_train_predict.index
df_train_actual['Index'] = df_train_actual.index

df_merged_train = pd.merge(df_train_actual, df_train_predict, on='Index')

df_merged_train.set_index('Index', inplace=True)

plt.plot(df_merged_train['Predicted'][0:100], label='Predicted')
plt.plot(df_merged_train['Actual'][0:100], label='Actual')
plt.title ('Vehicle Prediction - Train')
plt.legend()
plt.show()

val_predict = lstm(valX)

val_predict = val_predict.data.numpy()
val_actual = valY.data.numpy()
val_predict = sc.inverse_transform(val_predict)
val_actual = sc.inverse_transform(val_actual)

df_val_predict = pd.DataFrame(val_predict, columns=['Predicted'])
df_val_actual = pd.DataFrame(val_actual, columns=['Actual'])

df_val_predict['Index'] = df_val_predict.index
df_val_actual['Index'] = df_val_actual.index

df_merged_val = pd.merge(df_val_actual, df_val_predict, on='Index')

df_merged_val.set_index('Index', inplace=True)

plt.plot(df_merged_val['Predicted'][0:100], label='Predicted')
plt.plot(df_merged_val['Actual'][0:100], label='Actual')

plt.title ('Vehicle Prediction - Validation')
plt.legend()
plt.show()

test_predict = lstm(testX)

test_predict = test_predict.data.numpy()
test_actual = testY.data.numpy()
test_predict = sc.inverse_transform(test_predict)
test_actual = sc.inverse_transform(test_actual)

df_test_predict = pd.DataFrame(test_predict, columns=['Predicted'])
df_test_actual = pd.DataFrame(test_actual, columns=['Actual'])

df_test_predict['Index'] = df_test_predict.index
df_test_actual['Index'] = df_test_actual.index

df_merged_test = pd.merge(df_test_actual, df_test_predict, on='Index')

df_merged_test.set_index('Index', inplace=True)

plt.plot(df_merged_test['Predicted'][0:100], label='Predicted')
plt.plot(df_merged_test['Actual'][0:100], label='Actual')
plt.title ('Vehicle Prediction - Test')

plt.legend()
plt.show()

#part 2 using multivariate

traffic_df2=traffic_df[["DateTime","Vehicles"]]
traffic_df2['DateTime'] = pd.to_datetime(traffic_df['DateTime'])

traffic_df2['Seconds'] = (traffic_df2['DateTime'] - pd.Timestamp("1970-01-01")) // pd.Timedelta('1s')
traffic_df2 = traffic_df2[['DateTime', 'Vehicles', 'Seconds']]

day = 24*60*60
year = (365.2425)*day

traffic_df2['Day sin'] = np.sin(traffic_df2['Seconds'] * (2 * np.pi / day))
traffic_df2['Day cos'] = np.cos(traffic_df2['Seconds'] * (2 * np.pi / day))
traffic_df2['Year sin'] = np.sin(traffic_df2['Seconds'] * (2 * np.pi / year))
traffic_df2['Year cos'] = np.cos(traffic_df2['Seconds'] * (2 * np.pi / year))

traffic_df2=traffic_df2.drop("Seconds",axis=1)
traffic_df2=traffic_df2.drop("DateTime",axis=1)

traffic_df2.head

sc = MinMaxScaler()
data = sc.fit_transform(traffic_df2)
data= pd.DataFrame(data, columns=traffic_df2.columns)
data.head

def df_to_X_y2(df, window_size=6):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [r for r in df_as_np[i:i+window_size]]
    X.append(row)
    label = df_as_np[i+window_size][0]
    y.append(label)
  return np.array(X), np.array(y)

X2, y2 = df_to_X_y2(data)
X2.shape, y2.shape

X2_train, y2_train = X2[:30000], y2[:30000]
X2_val, y2_val = X2[30000:39000], y2[30000:39000]
X2_test, y2_test = X2[39000:], y2[39000:]
X2_train.shape, y2_train.shape, X2_val.shape, y2_val.shape, X2_test.shape, y2_test.shape

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

model4 = Sequential()
model4.add(InputLayer((6, 5)))
model4.add(LSTM(64))
model4.add(Dense(8, 'relu'))
model4.add(Dense(1, 'linear'))

model4.summary()

cp4 = ModelCheckpoint('model4/', save_best_only=True)
model4.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=[RootMeanSquaredError()])

model4.fit(X2_train, y2_train, validation_data=(X2_val, y2_val), epochs=30, callbacks=[cp4])

from sklearn.metrics import mean_squared_error as mse

def plot_predictions1(model,X,y,data_type,start=0, end=100):
  predictions = model.predict(X).flatten()
  df = pd.DataFrame(data={'Predictions': predictions, 'Actuals':y})
  plt.plot(df['Predictions'][start:end])
  plt.plot(df['Actuals'][start:end])
  plt.title(f'Vehicle Prediction - {data_type}')
  plt.legend()
  return df, mse(predictions, y)

plot_predictions1(model4, X2_train, y2_train, data_type='Train')

plot_predictions1(model4, X2_val, y2_val,data_type='Validation')

plot_predictions1(model4, X2_test, y2_test,data_type='Test')